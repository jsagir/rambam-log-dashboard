# Rambam System Dashboard

## Project Overview

A clean, visual dashboard showing activity and performance data from the Rambam (Maimonides) AI holographic experience at the Museum of Tolerance Jerusalem.

**Stack:** Vite + React 19 + Recharts + Tailwind CSS (museum-grade dark warm palette)
**Data:** `public/data/accumulated.json` (single file, generated by Python scripts)
**Deploy:** Render static site `rambam-dash-v2` (srv-d6fbtsggjchc73fl612g), auto-deploys on push to main
**Live URL:** https://rambam-dash-v2.onrender.com
**Environment:** `OPENAI_KEY` is available in Render environment variables for LLM-powered features

## Dashboard Navigation

The dashboard has two main views, accessible via prominent buttons at the top:

- **Cumulative Trends** â€” Overall performance across all days. Shows aggregated KPIs, topic trends, daily volume charts, and the full conversation feed. This is the default view.
- **Day Drill-Down** â€” Examine a specific day in detail. Shows KPIs, conversations, and charts filtered to one day. Navigate between days with arrow buttons or the date dropdown. Shows the day name, date, and conversation count in a gold banner.

**Color legend** (always visible): Green = Good, Yellow = Needs Attention, Red = Problem.

**Additional features:**
- **Translation toggle** â€” Show/hide English translations of Hebrew conversations
- **Faceted filters** â€” Topic, Language, Sensitivity, Latency, Anomaly, STOP command multi-filters
- **Ask the Data** â€” Sticky floating panel (bottom-right), GPT-4o-mini powered with local fallback
- **System Issues** â€” Collapsible section showing latency scatter, daily trends, anomaly breakdown

## Architecture: "Ask the Data"

**UI:** Sticky floating panel on the right side of the dashboard. Always available â€” click the gold "Ask the Data" button at bottom-right. Collapsible, resizable (compact/normal/large).

**Hybrid engine:**
1. **Primary: LLM-powered** (GPT-4o-mini via OpenAI proxy at `api/openai-proxy.cjs`)
   - Client builds a compact text summary of ALL conversations from accumulated.json
   - Sends `{ question, dataSummary }` to proxy at `VITE_ASK_PROXY_URL`
   - Proxy adds comprehensive system prompt (data schema, anomaly types, topic context)
   - GPT returns structured JSON: `{ filters, sort, mode, answer, stats, insights, follow_ups }`
   - Client applies returned filters to show matching conversation cards
   - Follow-up questions rendered as clickable chips
   - Indicator: brain emoji (ðŸ§ )
2. **Fallback: Local keyword engine** (when proxy unavailable or no OpenAI credits)
   - Topic alias matching, language/anomaly/stop/sensitivity filters
   - Comparison mode, text search, basic aggregation
   - Indicator: lightning bolt (âš¡)

**Proxy deployment:** Render Web Service `rambam-ask-proxy` (srv-d6ff035di7vc738pp26g)
- Source: `api/openai-proxy.cjs` (CommonJS â€” `.cjs` required because package.json has `"type": "module"`)
- Env: `OPENAI_KEY` (shared environment group with dashboard)
- URL: `https://rambam-ask-proxy.onrender.com/ask`

**Future (500+ conversations):** Add Pinecone vector retrieval before GPT to avoid sending all data in context.

## CRITICAL: Parallel Pipeline Latency Model

The Rambam system runs **two parallel pipelines** from T0 (STT completion):

```
T0: STT completes (visitor finishes speaking)
 â”œâ”€â”€ Pipeline A: classify â†’ select opening â†’ fire audio     â†’ T1 (avg 1.9s)
 â””â”€â”€ Pipeline B: LLM inference â†’ stream response chunks     â†’ T2 (avg 3.5s from T0)
```

Both start simultaneously. The opening audio (~3s) plays while the LLM finishes.

| Metric | Formula | Dashboard Label | What It Means | Healthy | Critical |
|--------|---------|----------------|---------------|---------|----------|
| **Silence Gap** | T1-T0 | "Silence Gap" | Opening pipeline time. Silence visitor FEELS. | <2s | >5s |
| **AI Behind Opening** | T2-T1 | "AI Behind Opening" | Remaining LLM time after opening fires. Covered by opening audio. | <3s | >5s |
| **AI Ready** | T2-T0 | "AI Ready" | Total LLM time. Answer buffered at this point. | <4s | >6s |
| **Stream Duration** | T3-T2 | â€” | Answer delivery time (TTS playback) | varies | >5s |

**The killer metric:** "Seamless Rate" = % where T2-T1 < opening_audio_duration (~3s). If the remaining LLM time fits within the opening audio, zero second gap after opening.

**Proof of parallel architecture:** 3 OUT_OF_ORDER cases (1.6% of data) where T2 < T1 â€” the LLM finished BEFORE the opening even fired. This is impossible in a sequential model.

**Anomaly types from this model:**
- `OPENING_LATENCY_WARN/CRITICAL` â€” visitor waited too long in silence (Pipeline A slow)
- `THINK_OVERFLOW` â€” remaining LLM time exceeded opening audio duration (second silence gap)
- `OUT_OF_ORDER` â€” T2 < T1, stream_chunk before waiting_audio (Starcloud bug: answer ready but not played)

**Precision note:** STT timestamps are second-precision; msg.timestamp is millisecond-precision. Silence gap has Â±1s uncertainty.

**Pending confirmation from Daniel:** Exact opening audio durations per audio_id would let us compute precise seamless rate and net_latency_ms.

**Fields in data:** `opening_latency_ms` (T1-T0), `ai_think_ms` (T2-T1), `stream_duration_ms` (T3-T2), `is_out_of_order` per conversation. `seamless_response_rate`, `avg_opening_latency_ms`, `avg_ai_think_ms` in KPIs.

## CRITICAL: STOP Safe Word / Kill Switch

The Rambam hologram has a **safe word system** â€” saying the trigger phrase mid-conversation kills Rambam's speech immediately, even mid-sentence. This is a control signal, not a conversation.

**Current trigger:** English **"Thank you"** (and variants: "thanks", "thank you very much", etc.)
**NOT a trigger:** Hebrew **"×ª×•×“×”"** â€” this is just polite conversation, does NOT stop Rambam.

**Important: The trigger word may change in the future.** The system is designed so that whatever word is chosen, we still need to detect and analyze its effect on conversations. The dashboard tracks:

- `is_thank_you_interrupt: true` â€” English kill switch detected (STOP badge, red)
- `thank_you_type: 'stop'` â€” English kill switch
- `thank_you_type: 'polite'` â€” Hebrew thanks (green badge, not a stop)
- `thank_you_type: null` â€” neither

**Edge cases handled:**
- "Thank you but what about..." â†’ NOT a stop (continuation detected)
- "Thank you. Tell me about..." â†’ NOT a stop (follow-up question)
- "Thank you, thank you." â†’ IS a stop (pure stop command)
- "Thank you, Rambam." â†’ IS a stop (polite stop)

**When the trigger word changes:** Update `STOP_PATTERNS` in `scripts/process_log.py` and re-process all logs.

## MANDATORY: Swarm Validation on Every New Log

**RULE:** Every time a new log file is processed, you MUST consult the three skills in `swarm/` to validate the data:

1. **`swarm/rambam-log-extractor.md`** â€” Run FIRST. Validates parsing, topic classification, anomaly detection. Check all quality gates.
2. **`swarm/rambam-viz-shaper.md`** â€” Run SECOND. Validates the data fits every dashboard component contract. Check latency integrity, chart renderability, anomaly consistency.
3. **`swarm/dataviz-consultant.md`** â€” Consult when adding/changing any visualization. Ensures charts communicate, not just display.

After processing a new log, report:
- Total conversations extracted
- Topic distribution (flag if "General" > 40%)
- Anomalies found (count + types)
- Latency stats (avg, median, P95, spikes)
- Any data contract violations

## MANDATORY: New Log Ingestion Pipeline

**When a new log file arrives, follow EVERY step. Do NOT skip steps.**

### Step 1: Add raw log

```bash
cp /path/to/new-log.txt logs/raw/YYYYMMDD.txt
# Naming: 20260225.txt, or 20260225-2.txt for second log same day
# Extension: always .txt (even though content is newline-delimited JSON)
```

### Step 2: Process all new logs

```bash
python3 scripts/process_all_new.py
```

This orchestrator does three things automatically:
1. Finds unprocessed `.txt` files in `logs/raw/` (compares stems against `logs/processed/`)
2. Runs `scripts/process_log.py` on each new file â€” parses JSON lines, groups interactions by msg.id, computes two-latency model, detects anomalies, classifies topics, translates Hebrew, detects STOP commands, outputs `logs/processed/YYYYMMDD.json`
3. Runs `scripts/build_accumulated.py` â€” merges ALL processed files into `public/data/accumulated.json` with deduplication, KPI aggregation, topic trends, and anomaly log

### Step 3: Validate with swarm (MANDATORY)

Run the three validation gates in order:
1. `swarm/rambam-log-extractor.md` â€” parsing quality, topic classification, anomaly detection
2. `swarm/rambam-viz-shaper.md` â€” data contract compliance, latency integrity, chart renderability
3. `swarm/dataviz-consultant.md` â€” visualization effectiveness

**Report after validation:**
- Total conversations extracted
- Topic distribution (flag if "General" > 40%)
- Anomalies found (count + types)
- Latency stats (avg, P95, spikes)
- Any data contract violations

### Step 4: Verify locally

```bash
npm run dev
# Open http://localhost:5173 and verify:
# - New day appears in Day Drill-Down dropdown
# - KPI numbers updated
# - Conversations visible in feed
# - No broken charts
```

### Step 5: Commit and deploy

```bash
git add logs/raw/YYYYMMDD.txt logs/processed/YYYYMMDD.json public/data/accumulated.json
git commit -m "feat: Add log data for YYYY-MM-DD (N interactions)"
git push origin main
# Render auto-deploys in 2-3 minutes
```

### Step 6: Notify if critical

If processing flagged **critical sensitivity** items, **VIP visitors**, or **system failures** â€” notify Daniel and museum management.

### Data flow diagram

```
logs/raw/YYYYMMDD.txt          (newline-delimited JSON: STT + AI messages)
    â†“ scripts/process_log.py   (parse, group, classify, detect anomalies, translate)
logs/processed/YYYYMMDD.json   (enriched interactions + daily summary)
    â†“ scripts/build_accumulated.py  (merge all, deduplicate IDs, aggregate KPIs)
public/data/accumulated.json   (single source of truth: meta + kpi + daily_stats + topic_trend + anomaly_log + conversations)
    â†“ Dashboard fetches at runtime
https://rambam-dash-v2.onrender.com
```

### Raw log format

Each line is JSON with `type` field:
- `{"type": "stt", "time": "2026/2/25 13:45:02", "msg": "visitor question text"}` â€” speech-to-text
- `{"type": "ai_message", ..., "msg": {"id": "UUID", "type": "waiting_audio", ...}}` â€” opening sentence dispatched (T1)
- `{"type": "ai_message", ..., "msg": {"id": "UUID", "type": "stream_chunk", "data": {"result": "...", "finished": false}}}` â€” LLM response chunks (T2, T3)

Events are grouped by `msg.id`. Latencies computed from timestamps: T0 (STT) â†’ T1 (waiting_audio) â†’ T2 (first chunk) â†’ T3 (last chunk).

### What process_log.py produces per interaction

```
id, date, time, hour, question, answer, question_en, answer_en,
language, question_type, topic, opening_text, audio_id,
latency_ms, opening_latency_ms, ai_think_ms, stream_duration_ms,
is_out_of_order, answer_length, chunk_count, is_complete,
is_greeting, is_thank_you_interrupt, thank_you_type,
is_comprehension_failure, is_no_answer, is_anomaly, anomaly_type,
anomalies[], sensitivity, vip, needs_translation
```

### Critical rules

1. **Chronological order** â€” interactions MUST be sorted by timestamp ascending
2. **ID deduplication** â€” overlapping logs produce duplicate msg.ids â†’ build_accumulated.py appends `_1`, `_2` suffixes
3. **No negative latencies** â€” if T1 < T0 (out-of-order bug), flag as `OUT_OF_ORDER`
4. **Topic quality gate** â€” if "General" > 40%, review keyword rules in process_log.py
5. **Translation** â€” all Hebrew conversations get English translations via Google Translate
6. **Sensitivity escalation** â€” `critical` items (idolatry, interfaith theology, modern politics) require human review
- **System health** - Is everything working well?
- **Items to review** - Any issues that need attention

## Dashboard Sections (Current Layout)

The dashboard renders in this order in `src/App.tsx`:

1. **Header** â€” Logo, title, date range, translation toggle
2. **Navigation** â€” Cumulative Trends / Day Drill-Down buttons + day selector
3. **KPI Band** (`src/components/kpi/KPIBand.tsx`) â€” 7 stat cards with sparklines:
   - Visitor Questions, Silence Gap (HE/EN), AI Ready (HE/EN), AI Behind Opening (HE/EN + seamless %), System Status, Languages, Problems
4. **What Visitors Are Asking** (`src/components/content/ContentIntelligence.tsx`) â€” 4 tabs:
   - **Visitor Questions** â€” Faceted conversation feed with filters (topic, language, sensitivity, latency, anomaly, STOP)
   - **Hot Topics** â€” Regex-based content classification into 20 categories with parent/child support (Religion > Christianity, Islam, Judaism). Bar chart + topic cards with sample questions.
   - **Opening Sentences** â€” All 66 opening sentences with categories (Statement, Open Questions, Closed Question, Generic, Personal/Current), inline audio playback (HE/EN), usage ranking, per-sentence stats. Data from `public/data/opening_sentences.json`.
   - **Topics & Trends** â€” Topic distribution charts, daily topic trends
5. **Response Speed** (`src/components/health/LatencyPanel.tsx`) â€” Parallel pipeline latency analysis:
   - Three cards: Silence Gap, AI Behind Opening, AI Ready
   - Per-language latency breakdown (Hebrew/English/Unknown) with avg, P95, seamless rate
   - Seamless rate bar with gap details
   - Daily trend chart
   - Histogram, scatter plot, SLA compliance, speed by topic/language/hour
   - 10 slowest answers table
6. **Operational Intelligence** (`src/components/health/OperationalIntelligence.tsx`) â€” 4 panels:
   - **Unknown Language Analysis** â€” Categorizes unknown conversations (Russian/Arabic/noise/real attempts)
   - **Uptime & Availability Calendar** â€” Day grid showing active/low/offline status
   - **Race Condition Trend** â€” OUT_OF_ORDER daily bar chart + case details
   - **Visitor Sessions (Inferred)** â€” 30-min gap session inference with engagement stats
7. **System Issues** (`src/components/health/SystemHealth.tsx`) â€” Collapsible: scatter, daily trend, anomaly breakdown, recent problems
8. **Talk with Rambam** (`src/components/content/TalkWithRambam.tsx`) â€” Collapsible iframe to Azure Static Apps demo
9. **Ask the Data** (`src/components/content/AskPanel.tsx`) â€” Sticky floating panel, GPT-4o-mini powered

## Actual File Structure

```
rambam-log-dashboard/
â”œâ”€â”€ CLAUDE.md                          # This file
â”œâ”€â”€ index.html                         # Entry point (Clarity analytics)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ App.tsx                        # Main layout, all zones
â”‚   â”œâ”€â”€ main.tsx                       # React entry
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ kpi/KPIBand.tsx           # Top KPI cards with sparklines
â”‚   â”‚   â”œâ”€â”€ content/
â”‚   â”‚   â”‚   â”œâ”€â”€ ContentIntelligence.tsx # Tab container
â”‚   â”‚   â”‚   â”œâ”€â”€ ConversationFeed.tsx   # Faceted conversation list
â”‚   â”‚   â”‚   â”œâ”€â”€ HotTopics.tsx          # Content-level topic classification
â”‚   â”‚   â”‚   â”œâ”€â”€ OpeningSentences.tsx   # Opening sentence analytics + audio
â”‚   â”‚   â”‚   â”œâ”€â”€ TopicCharts.tsx        # Topic distribution charts
â”‚   â”‚   â”‚   â”œâ”€â”€ AskPanel.tsx           # Ask the Data floating panel
â”‚   â”‚   â”‚   â””â”€â”€ TalkWithRambam.tsx     # Azure iframe
â”‚   â”‚   â””â”€â”€ health/
â”‚   â”‚       â”œâ”€â”€ LatencyPanel.tsx       # Parallel pipeline latency analysis
â”‚   â”‚       â”œâ”€â”€ SystemHealth.tsx       # Anomaly breakdown
â”‚   â”‚       â””â”€â”€ OperationalIntelligence.tsx # Unknown lang, uptime, race conditions, sessions
â”‚   â”œâ”€â”€ hooks/useAccumulatedData.ts    # Fetches accumulated.json
â”‚   â”œâ”€â”€ lib/utils.ts                   # formatLatency, getLatencyColor, etc.
â”‚   â””â”€â”€ types/dashboard.ts            # All TypeScript interfaces
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ process_log.py                 # Parse raw log â†’ enriched JSON
â”‚   â”œâ”€â”€ process_all_new.py             # Orchestrator: find new logs, process, build
â”‚   â””â”€â”€ build_accumulated.py           # Merge all processed â†’ accumulated.json
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ raw/                           # Raw .txt log files (YYYYMMDD.txt)
â”‚   â””â”€â”€ processed/                     # Enriched .json per day
â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ accumulated.json           # Single source of truth for dashboard
â”‚   â”‚   â”œâ”€â”€ audio_durations.json       # WAV file durations per audio_id
â”‚   â”‚   â””â”€â”€ opening_sentences.json     # Sentence metadata (category, text EN/HE)
â”‚   â””â”€â”€ audio/
â”‚       â”œâ”€â”€ he/                        # 66 Hebrew WAV files (ElevenLabs)
â”‚       â””â”€â”€ en/                        # 67 English WAV files (Azure TTS)
â”œâ”€â”€ api/openai-proxy.cjs               # Ask the Data proxy (deployed separately)
â””â”€â”€ swarm/                             # Validation skill files
```

## Post-Ingestion Analytical Report

After every log ingestion, provide this report to confirm the dashboard is analytically current:

```
=== LOG INGESTION REPORT: YYYY-MM-DD ===

VOLUME
- New conversations: N
- Total in dashboard: N (across N days)
- Date range: YYYY-MM-DD to YYYY-MM-DD

LANGUAGE BREAKDOWN
- Hebrew: N (N%)
- English: N (N%)
- Unknown: N (N%) â€” [Russian: N, Arabic: N, Noise: N]

LATENCY (per language)
- Hebrew:  Silence Gap avg Xs, AI Behind Opening avg Xs, Seamless N%
- English: Silence Gap avg Xs, AI Behind Opening avg Xs, Seamless N%
- Overall: Silence Gap avg Xs, AI Ready avg Xs, Seamless N%

HOT TOPICS (top 5 from new day)
1. Topic (N questions)
2. ...

OPERATIONAL
- Race conditions (OUT_OF_ORDER): N new cases
- Comprehension failures: N
- STOP commands: N
- Anomalies: N (types: ...)
- Uptime: N/N days operational

SESSIONS (inferred, new day)
- Estimated visitors: N
- Avg questions/session: N
- Avg dwell time: Nmin

ALERTS (items needing attention)
- [list any critical sensitivity, VIP, or system issues]
```

## Team Context

- **Daniel** â€” Project lead, asks about latency gaps and system architecture
- **Talya/KPMG** â€” AI/LLM team, returns "unknown" for unrecognized languages
- **David/Starcloud** â€” On-prem Unreal Engine, TTS, opening sentence pipeline
- **Changzhi** â€” Testing, reported race condition increase after model 4.1 upgrade
- **Boris** â€” Daily QA
- **Guy** â€” Hardware/IT
- **Jonathan (jsagi)** â€” Dashboard builder, daily log recipient

## Analytics Tracking

- **Microsoft Clarity** â€” Project ID `vn264efxwa`, snippet in index.html
